{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bd5d47e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import functions / classes from helper and text_pipeline script \n",
    "from helpers import prepare_df, calc_scores, check_class_balance, downsample, hard\n",
    "from text_pipeline import TextPrep\n",
    "\n",
    "#all appropriate imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle \n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c09a85af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py:4901: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "#load in dataframe\n",
    "reviews = pd.read_csv('../data/yelp.csv', index_col=0)\n",
    "#then use the prepare_df function to clean the dataframe and make our three classes (ranked 1-3) \n",
    "reviews = prepare_df(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "778f5b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': 118818, 1: 19651, 2: 19713, 3: 79454}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#next, going to split the entire dataframe into train and holdout\n",
    "df_train, df_holdout = train_test_split(reviews)\n",
    "#lets use the imported check class balance function\n",
    "labels = [1, 2, 3]\n",
    "check_class_balance(df_train, 'stars', labels=labels)\n",
    "#we can see that class3 ('Good') greatly outnumbers the rest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a49a0cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58953, 39606)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train), len(df_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64cc8ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': 58953, 1: 19651, 2: 19651, 3: 19651}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#going to use the imported downsample function \n",
    "df_train = downsample(df_train, 'stars')\n",
    "#sanity check\n",
    "check_class_balance(df_train, 'stars', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "868c3c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the TextPrep class which instatiates an NLP pipeline for a dataframe, \n",
    "#including a vectorize method which takes a method and a column name as a parameter \n",
    "pipeline = TextPrep(df_train)\n",
    "X = pipeline.vectorize('text', method='token')\n",
    "y = pd.get_dummies(df_train['stars']).values\n",
    "#the pipeline has a documents attribute which has a list of raw documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "960a2747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #create another pipeline for the un-undersampled holdout\n",
    "pipeline_holdout = TextPrep(df_holdout)\n",
    "X_holdout = pipeline_holdout.vectorize('text', method='token')\n",
    "y_holdout = pd.get_dummies(df_holdout['stars']).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b89be0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad7ed7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 0.33272267738707106 \n",
      "Accuracy : 0.33272267738707106 \n",
      "Recall: 0.33272267738707106\n"
     ]
    }
   ],
   "source": [
    "#first:establish a baseline, which is if prediction was just random (each class with equal probability)\n",
    "#then use the imported calc_scores function which returns a list of precision, accuracy, and recall score\n",
    "baseline = []\n",
    "for i in range(len(y)):\n",
    "    baseline.append(np.random.choice([1, 2, 3]))\n",
    "baseline = np.array(baseline)\n",
    "baseline_scores = calc_scores(baseline, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ba0ba139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 250, 100)          5000000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_3 (Spatial (None, 250, 100)          0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 5,080,703\n",
      "Trainable params: 5,080,703\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#next let's build layers of  lstm model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(50000, 100, input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.3))\n",
    "model.add(LSTM(100, dropout=0.4, recurrent_dropout=0.5))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4e9aa70f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "553/553 [==============================] - 632s 1s/step - loss: 0.8928 - accuracy: 0.5507 - val_loss: 0.6944 - val_accuracy: 0.6960\n",
      "Epoch 2/3\n",
      "553/553 [==============================] - 591s 1s/step - loss: 0.5864 - accuracy: 0.7501 - val_loss: 0.6701 - val_accuracy: 0.7082\n",
      "Epoch 3/3\n",
      "553/553 [==============================] - 670s 1s/step - loss: 0.4686 - accuracy: 0.8114 - val_loss: 0.6928 - val_accuracy: 0.7007\n"
     ]
    }
   ],
   "source": [
    "epochs=3\n",
    "batch_size=64\n",
    "history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=.2, \n",
    "                   callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "532adf39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 0.7045932559875161 \n",
      "Accuracy : 0.7045932559875161 \n",
      "Recall: 0.7045932559875161\n"
     ]
    }
   ],
   "source": [
    "#now lets test the model's predictions \n",
    "#since the lstm model is a soft classifier, \n",
    "#use the imported hard function to harden the predictions \n",
    "y_hat = hard(model.predict(X_test))\n",
    "test_scores = calc_scores(hard(y_test), y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "44942551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 0.29937383224763925 \n",
      "Accuracy : 0.29937383224763925 \n",
      "Recall: 0.29937383224763925\n"
     ]
    }
   ],
   "source": [
    "final_hat = hard(model.predict(X_holdout))\n",
    "final_scores = calc_scores(hard(y_holdout), final_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "77284b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#severly overfitting....should i try not to undersample? \n",
    "df_train2, df_holdout2 = train_test_split(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "edc9f715",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline2 = TextPrep(df_train2)\n",
    "X2 = pipeline2.vectorize('text', method='token')\n",
    "y2 = pd.get_dummies(df_train2['stars']).values\n",
    "pipeline_holdout2 = TextPrep(df_holdout2)\n",
    "X_holdout2 = pipeline_holdout2.vectorize('text', method='token')\n",
    "y_holdout2 = pd.get_dummies(df_holdout2['stars']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7f741aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d5f0271a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1114/1114 [==============================] - 1145s 1s/step - loss: 0.6854 - accuracy: 0.7262 - val_loss: 0.5131 - val_accuracy: 0.7918\n",
      "Epoch 2/3\n",
      "1114/1114 [==============================] - 1027s 921ms/step - loss: 0.4672 - accuracy: 0.8112 - val_loss: 0.5247 - val_accuracy: 0.7973\n",
      "Epoch 3/3\n",
      "1114/1114 [==============================] - 1243s 1s/step - loss: 0.4030 - accuracy: 0.8404 - val_loss: 0.4914 - val_accuracy: 0.8031\n"
     ]
    }
   ],
   "source": [
    "epochs=3\n",
    "batch_size=64\n",
    "history = model.fit(X2_train, y2_train, epochs=epochs, batch_size=batch_size, validation_split=.2, \n",
    "                   callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6a8666d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "929/929 [==============================] - 110s 119ms/step - loss: 0.4842 - accuracy: 0.8082\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.48419684171676636, 0.8082141280174255]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X2_test, y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5e8ccb00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1238/1238 [==============================] - 165s 133ms/step - loss: 1.2730 - accuracy: 0.5845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2729711532592773, 0.5844821333885193]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_holdout2, y_holdout2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab067c3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
