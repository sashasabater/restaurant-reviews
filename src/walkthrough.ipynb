{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "59631fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import functions / classes from helper and text_pipeline script \n",
    "from helpers import prepare_df, calc_scores, check_class_balance, downsample, hard\n",
    "from text_pipeline import TextPrep\n",
    "\n",
    "#all appropriate imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle \n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdb3d8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py:4901: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "#load in dataframe\n",
    "reviews = pd.read_csv('../data/yelp.csv', index_col=0)\n",
    "#then use the prepare_df function to clean the dataframe and make our three classes (ranked 1-3) \n",
    "reviews = prepare_df(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37107faf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': 118818, 1: 19705, 2: 19771, 3: 79342}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#next, going to split the entire dataframe into train and holdout\n",
    "df_train, df_holdout = train_test_split(reviews)\n",
    "#lets use the imported check class balance function\n",
    "labels = [1, 2, 3]\n",
    "check_class_balance(df_train, 'stars', labels=labels)\n",
    "#we can see that class3 ('Good') greatly outnumbers the rest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35579e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total': 59115, 1: 19705, 2: 19705, 3: 19705}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#going to use the imported downsample function \n",
    "df_train = downsample(df_train, 'stars')\n",
    "#sanity check\n",
    "check_class_balance(df_train, 'stars', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27976fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the TextPrep class which instatiates an NLP pipeline for a dataframe, \n",
    "#including a vectorize method which takes a method and a column name as a parameter \n",
    "pipeline = TextPrep(df_train)\n",
    "X = pipeline.vectorize('text', method='token')\n",
    "y = df_train['stars'].values\n",
    "#the pipeline has a documents attribute which has a list of raw documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da5e648c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #create another pipeline for the un-undersampled holdout\n",
    "pipeline_holdout = TextPrep(df_holdout)\n",
    "X_holdout = pipeline_holdout.vectorize('text', method='token')\n",
    "y_holdout = df_holdout['stars'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e2dc2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a73d8743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 0.33340099805463924 \n",
      "Accuracy : 0.33340099805463924 \n",
      "Recall: 0.33340099805463924\n"
     ]
    }
   ],
   "source": [
    "#first:establish a baseline, which is if prediction was just random (each class with equal probability)\n",
    "#then use the imported calc_scores function which returns a list of precision, accuracy, and recall score\n",
    "baseline = []\n",
    "for i in range(len(y)):\n",
    "    baseline.append(np.random.choice([1, 2, 3]))\n",
    "baseline = np.array(baseline)\n",
    "baseline_scores = calc_scores(baseline, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ff962abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#next load in the lstm model. It has already been trained with the following architecture:\n",
    "# model = Sequential()\n",
    "# model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X_lstm.shape[1]))\n",
    "# model.add(SpatialDropout1D(0.2))\n",
    "# model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "# model.add(Dense(3, activation='softmax'))\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5ac00344",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('lstm_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82e2a29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
