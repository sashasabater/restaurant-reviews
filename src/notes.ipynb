{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from numpy.linalg import svd as SVD\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score \n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pickle\n",
    "%matplotlib inline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv('../data/yelp.csv', index_col=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this column is empty \n",
    "reviews.drop('business_neighborhoods', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i want to only deal with restaurants \n",
    "reviews = reviews[reviews['business_categories'].str.contains('Restaurant') == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are six entries with no text review, going to drop \n",
    "no_rev = reviews[pd.isna(reviews['text']) == True].index \n",
    "reviews.drop(labels=no_rev, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews.reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.hist(reviews['stars'], color = 'lightcoral')\n",
    "ax.set_xticks(np.arange(1,6))\n",
    "ax.set_xlabel('star rating')\n",
    "ax.set_ylabel('frequency')\n",
    "ax.set_title('Frequency of Star Ratings')\n",
    "plt.savefig('../img/ratings-hist.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#why don't i model based on the vectorized feature matrix of the text component of reviews\n",
    "#going to begin with a simple baseline (the mean), then move onto a logistic regressor \n",
    "#first going to split the data into training, testing, and holdout \n",
    "# X = vectorized.toarray()\n",
    "# Y = reviews['stars'].values\n",
    "# x, X_holdout, y, y_holdout = train_test_split(X, Y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_pipeline import TextPrep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline = TextPrep(reviews)\n",
    "# X = pipeline.vectorize('text')\n",
    "# my imported class keeps throwing an error so going to just manually import function for now "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(df ,column, method='tfidf'):\n",
    "        #takes in name of column to be cleaned, and method to vectorize\n",
    "        lem = WordNetLemmatizer()\n",
    "        #lemmatizing as opposed to stemming \n",
    "        s_words = stopwords.words('english')\n",
    "        texts = []\n",
    "        for doc in df[column].values:\n",
    "            cleaned = [lem.lemmatize(word).lower() for word in doc.split(' ') \\\n",
    "                       if word not in s_words and word.isalpha() == True]\n",
    "            #making sure that every word onl\n",
    "            texts.append(' '.join(cleaned))\n",
    "  \n",
    "        if method == 'tfidf':\n",
    "            vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "            vectorized = vectorizer.fit_transform(texts).toarray()\n",
    "            return vectorized\n",
    "            #creating a feature names attribute(bag of words)\n",
    "        elif method == 'count':\n",
    "            vectorizer = CountVectorizer(stop_words='english', max_features=5000)\n",
    "            vectorized = vectorizer.fit_transform(self.documents).toarray()\n",
    "            return vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = vectorize(reviews, 'text')\n",
    "y = reviews['stars'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores(y_true, y_predict):\n",
    "    precision = precision_score(y_true, y_predict,average='macro')\n",
    "    accuracy = accuracy_score(y_true, y_predict)\n",
    "    recall = recall_score(y_true, y_predict, average='macro')\n",
    "    print(f'Precision : {precision} \\n'  \n",
    "          f'Accuracy : {accuracy} \\n'\n",
    "         f'Recall: {recall}')\n",
    "    return [precision, accuracy, recall]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 0.07320229258193203 \n",
      "Accuracy : 0.36601146290966013 \n",
      "Recall: 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#baseline will be the mode, 4\n",
    "y_mode = np.array([4] * len(y))\n",
    "baseline_ = scores(y, y_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now lets make proper splits \n",
    "X_train, X_holdout, y_train, y_holdout = train_test_split(x, y)\n",
    "X_subtrain, X_subtest, y_subtrain, y_subtest = train_test_split(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/user/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#going to start with simple logistic regression and check the error \n",
    "log_model = LogisticRegression().fit(X_subtrain, y_subtrain)\n",
    "yhat_log = log_model.predict(X_subtest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 0.5080392677608373 \n",
      "Accuracy : 0.5206867530718734 \n",
      "Recall: 0.4665495774252085\n"
     ]
    }
   ],
   "source": [
    "scores(y_subtest, yhat_log)\n",
    "#lets pickle the model \n",
    "pickle.dump(log_model, open('log_model.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 0.5107873954553696 \n",
      "Accuracy : 0.5298187143362116 \n",
      "Recall: 0.4695066393621798\n"
     ]
    }
   ],
   "source": [
    "final_yhat_log = log_model.predict(X_holdout)\n",
    "log_scores = scores(y_holdout,final_yhat_log)\n",
    "#results for logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 0.46370944265991304 \n",
      "Accuracy : 0.46712674633900014 \n",
      "Recall: 0.3622393236900735\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.46370944265991304, 0.46712674633900014, 0.3622393236900735]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#randomforestnext - out of box first then will gridsearch.\n",
    "rm = RandomForestClassifier(class_weight='balanced').fit(X_subtrain, y_subtrain)\n",
    "rm_hat = rm.predict(X_subtest)\n",
    "scores(y_subtest, rm_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i have alreaedy done a grid search, not shown here due to computational cost\n",
    "rm_final = RandomForestClassifier(class_weight='balanced_subsample', max_samples=.5).fit(X_subtrain, y_subtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 0.46872207598811944 \n",
      "Accuracy : 0.468944099378882 \n",
      "Recall: 0.35804206652494236\n"
     ]
    }
   ],
   "source": [
    "rm_final_hat = rm_final.predict(X_holdout)\n",
    "rm_scores = scores(y_holdout, rm_final_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-00cbfc90b3ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#lets move on to gradient boosting - after this going to undersample to figure out class imbalance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_subtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_subtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m         n_stages = self._fit_stages(\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m             sample_weight_val, begin_at_stage, monitor)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m             \u001b[0;31m# fit next stage of trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m             raw_predictions = self._fit_stage(\n\u001b[0m\u001b[1;32m    562\u001b[0m                 \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m                 random_state, X_csc, X_csr)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_gb.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0m\u001b[1;32m    215\u001b[0m                      check_input=False)\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1250\u001b[0m         \"\"\"\n\u001b[1;32m   1251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1252\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m   1253\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    392\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#lets move on to gradient boosting - after this going to undersample to figure out class imbalance \n",
    "gb = GradientBoostingClassifier().fit(X_subtrain, y_subtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9fdced22d77102b5601c8f6ec647391a5080fbbd8dc561881d6412554a470c13"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
